{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import requests\n",
    "from collections import Counter\n",
    "from num2words import num2words\n",
    "from nltk.corpus import cmudict\n",
    "cmudict = cmudict.dict()\n",
    "import copy\n",
    "import torch\n",
    "import json\n",
    "import TextAnalyzer as ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gethaikus(text):\n",
    "    haikus = pd.Series(text.split(\"\\n\\n\"))\n",
    "    return haikus\n",
    "\n",
    "\n",
    "source_root = \"Haikus\"\n",
    "\n",
    "# Source 1\n",
    "text = open(source_root + \"/haikuzao.txt\", \"r\").read()\n",
    "text = text.lower()\n",
    "haikus = gethaikus(text)\n",
    "# Source 2\n",
    "gutenberg = pd.read_csv(source_root + \"/gutenberg.csv\")\n",
    "haikus = haikus.append(\n",
    "    pd.Series(gutenberg[\"haiku\"]).apply(lambda x: x.lower())\n",
    ")\n",
    "# Source 3\n",
    "modern_renaissance = pd.read_csv(source_root + \"/modern_renaissance.csv\")\n",
    "# make lower case and ensure that the new line notation is the same\n",
    "modern_renaissance = pd.Series(modern_renaissance[\"content\"]).apply(\n",
    "    lambda x: x.lower().replace(\"\\r\\n\", \"\\n\")\n",
    ")\n",
    "haikus = haikus.append(modern_renaissance)\n",
    "# Source 4\n",
    "sballas = pd.read_csv(source_root + \"/sballas8.csv\", header=None)\n",
    "haikus = haikus.append(pd.Series(sballas[0]))\n",
    "# Source 5\n",
    "temps = pd.read_csv(source_root + \"/tempslibres.csv\", encoding=\"ISO-8859-1\")\n",
    "# Only English\n",
    "temps = temps[temps[\"lang\"] == \"en\"]\n",
    "# make lower case and ensure that the new line notation is the same\n",
    "haikus = haikus.append(\n",
    "    pd.Series(temps[\"haiku\"]).apply(lambda x: x.lower().replace(\"\\r\\n\", \"\\n\"))\n",
    ")\n",
    "# Source 6\n",
    "hjson = pd.read_json(source_root + \"/unim_poem.json\")\n",
    "haikus = haikus.append(pd.Series(hjson[\"poem\"])).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean words with text format class\n",
    "formatter = ta.TextFormat()\n",
    "\n",
    "def cleanwords(text):\n",
    "    text = text.replace(\"-\", \" \")\n",
    "    text = text.replace(\"'\", \"\")\n",
    "    text = formatter.numtotext(text)\n",
    "    return text\n",
    "\n",
    "\n",
    "haikus = haikus.apply(cleanwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CMUDICT and use it to instantiate a transformer class\n",
    "ptransformer = ta.PhonemeTransform(cmudict)\n",
    "# Get Full text and list of Words\n",
    "text = formatter.arraytotext(haikus)\n",
    "words = formatter.getwords(text)\n",
    "# Find unknownwords\n",
    "unknowns = ptransformer.getunknowns(words)\n",
    "# Split unknown words to find two words within one; add to dictionary\n",
    "ptransformer.addsplitwords(unknowns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes in haikus and separates haikus that have words not in the CMUDICT\n",
    "def splithaikus(haikus, pdict):\n",
    "\n",
    "    bad_haikus = []\n",
    "    good_haikus = []\n",
    "\n",
    "    for haiku in haikus:\n",
    "        words = formatter.getwords(haiku)\n",
    "        if all(word in pdict.keys() for word in words):\n",
    "            good_haikus.append(haiku)\n",
    "        else:\n",
    "            bad_haikus.append(haiku)\n",
    "\n",
    "    return bad_haikus, good_haikus\n",
    "\n",
    "\n",
    "bad_haikus, valid_haikus = splithaikus(haikus, ptransformer.phodict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "haikus_transformed = pd.Series(map(ptransformer.transform, valid_haikus))\n",
    "# Convert all syllables to 0\n",
    "haikus_transformed = pd.Series(\n",
    "    map(ptransformer.convertsyllables, haikus_transformed)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Inverted Phoneme Dictionary\n",
    "idict = ptransformer.invertdictionary()\n",
    "# Use Inverted Phoneme Dictionary and Regular Dictionary to instantiate class\n",
    "rtransformer = ta.PhonemeReverse(ptransformer.phodict, idict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return Haikus Back to Text\n",
    "haiku_text = formatter.arraytotext(haikus_transformed)\n",
    "# Get all words\n",
    "words = formatter.getwords(haiku_text)\n",
    "# Get syllables for each word\n",
    "syllables = words.apply(ptransformer.syllablecount)\n",
    "# zip lists together\n",
    "syll_list = [*zip(words, syllables)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list of words into 5-7-5 snippets\n",
    "haikus17 = []\n",
    "while len(syll_list) > 17:\n",
    "    cum = 0\n",
    "    haiku = []\n",
    "    \n",
    "    for i,tup in enumerate(syll_list):\n",
    "        cum = cum + tup[1]\n",
    "        if cum < 17:      \n",
    "            haiku.append(syll_list.pop(i)[0])\n",
    "\n",
    "        elif cum == 17:\n",
    "            haiku.append(syll_list.pop(i)[0])\n",
    "            haiku.append(\"\\n\")\n",
    "            haikus17.append(haiku)\n",
    "            break\n",
    "            \n",
    "        else:\n",
    "            cum = cum - tup[1]\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OW0NLIY0',\n",
       " 'DAY0VER0Z',\n",
       " 'DEH0SAH0LAH0T',\n",
       " 'DHAH0',\n",
       " 'DHAH0',\n",
       " 'RAY0T',\n",
       " 'JHEH0NTLIY0',\n",
       " 'TUW0',\n",
       " 'IH0KWEY0TER0',\n",
       " 'NAY0TS',\n",
       " '\\n']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to see if Haikus are 17 syllables structure\n",
    "haikus17[len(haikus17) - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['only',\n",
       " 'divers',\n",
       " 'desolate',\n",
       " 'the',\n",
       " 'the',\n",
       " 'right',\n",
       " 'gently',\n",
       " 'to',\n",
       " 'equator',\n",
       " 'knights']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rtransformer.getenglish(\n",
    "    formatter.arraytotext(haikus17[len(haikus17) - 1]), runs=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Haikus to CSV so transformations do not have to be ran again\n",
    "haiku_series = pd.Series(haikus17)\n",
    "haiku_series = haiku_series.apply(formatter.arraytotext)\n",
    "haiku_series.to_csv(\n",
    "    \"Haikus/PhonemeHaikusStructured.csv\", index=False, header=False\n",
    ")\n",
    "# Also output dictionaries so they do not have to be recreated when testing\n",
    "# CMUDICT with added split words\n",
    "with open(\"pdict.json\", \"w\") as fp:\n",
    "    json.dump(ptransformer.phodict, fp)\n",
    "\n",
    "# Inverse of CMUDICt with added split words\n",
    "with open(\"idict.json\", \"w\") as fp:\n",
    "    json.dump(idict, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
